data_set_config:
    data_type: kaldi
    label_dict: ?
    unk: '<unk>'
    space: ' '
    eos_key: '<eos>'
    jconfig:
        batch_size: 64
        max_length_in: 512
        max_length_out: 150
        num_batches: 0
        min_batch_size: 1
        shortest_first: True
        batch_sort_key: "feats"
        swap_io: False
        count: "seq"
        batch_bins: 5992000
        batch_frames_in: 0
        batch_frames_out: 0
        batch_frames_inout: 0
        clean_data: False
        
train_process_config:
  # these three processes are a.k.a. SpecAugument
    feats:
      - type: "time_warp"
        max_time_warp: 5
        inplace: true
        mode: "PIL"
      - type: "freq_mask"
        F: 30
        n_mask: 2
        inplace: true
        replace_with_zero: false
      - type: "time_mask"
        T: 40
        n_mask: 2
        inplace: true
        replace_with_zero: false

valid_process_config: false

opti_config:
    name: 'eteh.modules.pytorch_backend.optimizer.optimizer:Noam'
    factor: 1
    warm_step: 25000
    model_size: 320
    
criterion_config:
    name: 'local.TSE_KWS.model.e2e_loss_tse:CTC_CE_TSE_Loss'
    size: ?
    padding_idx: -1
    smoothing: 0.1
    rate: 0.3    
    tse_rate: 1.0
    tse_delay: True

model_config:
    name: 'local.TSE_KWS.model.e2e_transformer_tse:E2E_Transformer_CTC_TSE'
    idim: ?
    odim: ?
    encoder_attention_dim: 320
    encoder_attention_heads: 8
    encoder_linear_units: 2048
    encoder_num_blocks_share: 17
    encoder_num_blocks_asr: 0
    encoder_num_blocks_tse: 1
    encoder_input_layer: conv2d
    encoder_dropout_rate: 0.1
    encoder_attention_dropout_rate: 0
    decoder_attention_dim: 320
    decoder_attention_heads: 8
    decoder_linear_units: 2048
    decoder_num_blocks_share: 6
    decoder_num_blocks_asr: 0
    decoder_num_blocks_tse: 0
    decoder_input_layer: embed
    decoder_dropout_rate: 0.1
    decoder_src_attention_dropout_rate: 0
    decoder_self_attention_dropout_rate: 0
    ctc_dropout: 0.1
    tse_dim: 256
    fix_asr_params: True

train_config: 
    accum_grad: 1 #must be 1 when amp is used
    amp: false #[false, amp, apex:O1, apex:O2, apex:O3]
    char_num: ? #[you can add any key and value according to your own task]
    
decode_config:
    beam: 10
    ctc_beam: 15
    lm_rate: 0
    ctc_weight: 0.3
    char_num: ?
